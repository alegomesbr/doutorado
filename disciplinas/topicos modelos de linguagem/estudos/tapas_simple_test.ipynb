{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "import pandas as pd\n",
        "from transformers import TapasTokenizer, TapasConfig, TapasForQuestionAnswering"
      ],
      "metadata": {
        "id": "fSep879zYQXN"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = TapasConfig.from_pretrained(\"google/tapas-base-finetuned-wtq\")\n",
        "model = TapasForQuestionAnswering.from_pretrained(\"google/tapas-base-finetuned-wtq\", config=config)\n",
        "\n",
        "tokenizer = TapasTokenizer.from_pretrained(\"google/tapas-base-finetuned-wtq\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnxwfKIj_o-7",
        "outputId": "362eab4c-bd1b-407f-da6f-44e64e912d01"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    \"Titles\": [\"Glorious visions in animation and performance\",\"Medicine for the 99 percent\",\"What is so special about the human brain?\",\"The mysterious science of pain\",\"The uncomplicated truth about women's sexuality\"],\n",
        "    \"Views\": [\"946000\",\"310677\",\"3082440\",\"887739\",\"2303625\"],\n",
        "    \"Speakers\": [\"Miwa Matreyek\",\"Thomas Pogge\",\"Suzana Herculano-Houzel\",\"Joshua Pate\",\"Sarah Barmak\"],\n",
        "    \"Duration\": [\"671\",\"1085\",\"811\",\"287\",\"680\"],\n",
        "    \"Comments\": [\"148\",\"121\",\"1050\",\"0\",\"17\"],\n",
        "    \"Events\": [\"TEDGlobal 2010\",\"TEDxCanberra\",\"TEDGlobal 2013\",\"TED-Ed\",\"TEDxToronto\"]\n",
        "}\n",
        "\n",
        "queries = [\"what is the title with more comments?\",\"what is the event with the longest duration?\", \"How many speakers are there in the dataset?\"]\n",
        "\n",
        "table = pd.DataFrame.from_dict(data)\n",
        "inputs = tokenizer(table=table, queries=queries, padding=\"max_length\", return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n",
        "\n",
        "predicted_answer_coordinates, predicted_aggregation_indices = tokenizer.convert_logits_to_predictions(\n",
        "    inputs, outputs.logits.detach(), outputs.logits_aggregation.detach()\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZO1dcv0J_vzw",
        "outputId": "93d04e72-2003-4d89-a2c6-de646a40b623"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/tapas/tokenization_tapas.py:2699: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  text = normalize_for_match(row[col_index].text)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/tapas/tokenization_tapas.py:1493: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  cell = row[col_index]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3 perguntas e 2 acertos**.\n",
        "\n",
        "Na 3a pergunta ele acertou o agg, mas retornou a contagem de itens da lista respsota"
      ],
      "metadata": {
        "id": "7x7sIqMI7w4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id2aggregation = {0: \"NONE\", 1: \"SUM\", 2: \"AVERAGE\", 3: \"COUNT\"}\n",
        "aggregation_predictions_string = [id2aggregation[x] for x in predicted_aggregation_indices]\n",
        "answers = []\n",
        "\n",
        "for coordinates in predicted_answer_coordinates:\n",
        "    if len(coordinates) == 1:\n",
        "        # only a single cell:\n",
        "        answers.append(table.iat[coordinates[0]])\n",
        "    else:\n",
        "        # multiple cells\n",
        "        cell_values = []\n",
        "\n",
        "        for coordinate in coordinates:\n",
        "            cell_values.append(table.iat[coordinate])\n",
        "\n",
        "        answers.append(\", \".join(cell_values))\n",
        "\n",
        "for query, answer, predicted_agg in zip(queries, answers, aggregation_predictions_string):\n",
        "    print(query)\n",
        "    if predicted_agg == \"NONE\":\n",
        "        print(\"Predicted answer: \" + answer)\n",
        "    else:\n",
        "        print(\"Predicted answer: \" + predicted_agg + \" > \" + answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1hYq9dIA-ak",
        "outputId": "5774fafc-9974-48d6-af92-58afdb8c3c93"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what is the title with more comments?\n",
            "Predicted answer: What is so special about the human brain?\n",
            "what is the event with the longest duration?\n",
            "Predicted answer: TEDxCanberra\n",
            "How many speakers are there in the dataset?\n",
            "Predicted answer: COUNT > Miwa Matreyek, Thomas Pogge, Suzana Herculano-Houzel, Joshua Pate, Sarah Barmak\n"
          ]
        }
      ]
    }
  ]
}