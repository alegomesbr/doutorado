{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import TapexTokenizer, BartForConditionalGeneration"
      ],
      "metadata": {
        "id": "C8JjZFMm0VKY"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "C77Xk9XjSTTg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f243a25b-df00-4d18-fb8b-8d855dfa568d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#microsoft/tapex-base-finetuned-wtq\n",
        "#https://huggingface.co/microsoft/tapex-base-finetuned-wtq\n",
        "\n",
        "#microsoft/tapex-base-finetuned-wikisql\n",
        "#https://huggingface.co/microsoft/tapex-base-finetuned-wikisql\n",
        "\n",
        "#microsoft/tapex-base-finetuned-tabfact\n",
        "#https://huggingface.co/microsoft/tapex-base-finetuned-tabfact\n",
        "\n",
        "tokenizer = TapexTokenizer.from_pretrained(\"microsoft/tapex-base-finetuned-wikisql\")\n",
        "model = BartForConditionalGeneration.from_pretrained(\"microsoft/tapex-base-finetuned-wikisql\")\n",
        "\n",
        "data = {\n",
        "    \"Titles\": [\"Glorious visions in animation and performance\",\"Medicine for the 99 percent\",\"What is so special about the human brain?\",\"The mysterious science of pain\",\"The uncomplicated truth about women's sexuality\"],\n",
        "    \"Views\": [\"946000\",\"310677\",\"3082440\",\"887739\",\"2303625\"],\n",
        "    \"Speakers\": [\"Miwa Matreyek\",\"Thomas Pogge\",\"Suzana Herculano-Houzel\",\"Joshua Pate\",\"Sarah Barmak\"],\n",
        "    \"Duration\": [\"671\",\"1085\",\"811\",\"287\",\"680\"],\n",
        "    \"Comments\": [\"148\",\"121\",\"1050\",\"0\",\"17\"],\n",
        "    \"Events\": [\"TEDGlobal 2010\",\"TEDxCanberra\",\"TEDGlobal 2013\",\"TED-Ed\",\"TEDxToronto\"]\n",
        "}\n",
        "\n",
        "table = pd.DataFrame.from_dict(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**exemplo 1: pergunta com resposta correta**"
      ],
      "metadata": {
        "id": "9UihVtG50JAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tapex accepts uncased input since it is pre-trained on the uncased corpus\n",
        "query = \"what is the title with more comments?\"\n",
        "\n",
        "encoding = tokenizer(table=table, query=query, return_tensors=\"pt\")\n",
        "\n",
        "outputs = model.generate(**encoding)\n",
        "\n",
        "tokenizer.batch_decode(outputs, skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1_vWVIuzzhH",
        "outputId": "2dfe7101-2366-4fe6-def1-99f73a0ad74b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' what is so special about the human brain?']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**exemplo 2: pergunta com resposta errada**"
      ],
      "metadata": {
        "id": "6IaoH9nQ0OaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what is the event with the longest duration?\"\n",
        "\n",
        "encoding = tokenizer(table=table, query=query, return_tensors=\"pt\")\n",
        "\n",
        "outputs = model.generate(**encoding)\n",
        "\n",
        "tokenizer.batch_decode(outputs, skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D45BCtMSz1el",
        "outputId": "b5e399da-f33a-4759-f17f-a4d1589f2415"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' tedglobal 2013']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    }
  ]
}